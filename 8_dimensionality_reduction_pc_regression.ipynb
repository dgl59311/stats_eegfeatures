{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2dad6a4",
   "metadata": {},
   "source": [
    "## 8) Dimensionality reduction and multiple regression\n",
    "\n",
    "- EEG features showing a significant correlation to a cognitive variable were analyzed using PCA\n",
    "- The latent variables obtained using PCA were used to predict the cognitive variables\n",
    "- We first, used a regressor with one PC and then, we added one by one the rest PCs\n",
    "\n",
    "Gordillo, da Cruz, Moreno, Garobbio, Herzog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58172633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec265446",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = os.getcwd()\n",
    "np.random.seed(234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda4ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define results directories\n",
    "data_dir = os.path.join(main_dir, 'data')\n",
    "results_dir = os.path.join(main_dir, 'results')\n",
    "results_1_dir = os.path.join(results_dir, '1_correlations_eeg_beh_results')\n",
    "results_4_dir = os.path.join(results_dir, '4_correlations_groups_results')\n",
    "results_8_dir = os.path.join(results_dir, '8_pca_results')\n",
    "\n",
    "# behavior variables\n",
    "beh_vars = [\"Cvlt_attention_span\", \"Cvlt_delayed_memory\", \"Pts-2_subtest_3\",\n",
    "            \"Rwt_animal_categories\", \"Rwt_s_words\", \"Tap_alertness\",\n",
    "            \"Tap_simon_congruent\", \"Tap_simon_incongruent\", \"Tap_working_memory\",\n",
    "            \"Tmt-A\", \"Tmt-B\", \"Vocabulary_test\"]\n",
    "\n",
    "# which group\n",
    "idgroup = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4299c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data for PCA analysis\n",
    "\n",
    "# results files\n",
    "files_1 = os.listdir(results_1_dir)\n",
    "\n",
    "# correlation data\n",
    "sp_data = 'spearman_' + idgroup\n",
    "dc_data = 'distcorr_' + idgroup\n",
    "data_mask_sp = pd.read_csv(os.path.join(results_1_dir, '1_mask_' + sp_data + '.csv'), index_col=0)\n",
    "data_mask_dc = pd.read_csv(os.path.join(results_1_dir, '1_mask_' + dc_data + '.csv'), index_col=0)\n",
    "spearman_max = pd.read_csv(os.path.join(results_1_dir, '1_maxcorrvals_' + sp_data + '.csv'), index_col=0)\n",
    "distcorr_max = pd.read_csv(os.path.join(results_1_dir, '1_maxcorrvals_' + dc_data + '.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = beh_vars[0]\n",
    "vec_mask_sp = data_mask_sp[task].loc[data_mask_sp[task] != 'NS']\n",
    "n_feats_sp = len(vec_mask_sp)\n",
    "n_feats_sp\n",
    "list(filter(lambda x: '1_variables_eeg_' + task + '_' + sp_data in x, files_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c448a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for each task\n",
    "for k in range(len(beh_vars)):\n",
    "    \n",
    "    n_feats_sp = 0\n",
    "    n_feats_dc = 0\n",
    "\n",
    "    task = beh_vars[k]\n",
    "    \n",
    "    # load file showing which EEG features correlated significantly with the cognitive variable\n",
    "    \n",
    "    # Spearman correlations\n",
    "    vec_mask_sp = data_mask_sp[task].loc[data_mask_sp[task] != 'NS']\n",
    "    n_feats_sp = len(vec_mask_sp)\n",
    "    \n",
    "    # Distance correlations\n",
    "    vec_mask_dc = data_mask_dc[task].loc[data_mask_dc[task] != 'NS']\n",
    "    n_feats_dc = len(vec_mask_dc)\n",
    "    \n",
    "    data_results = []\n",
    "    \n",
    "    if n_feats_sp > 1:\n",
    "        \n",
    "        str_corr_sp = list(filter(lambda x: '1_variables_eeg_' + task + '_' + sp_data in x, files_1))\n",
    "        data_results = pd.read_csv(os.path.join(results_1_dir, str_corr_sp[0]), index_col=0)\n",
    "        task_out = data_results[task]\n",
    "        # Power transform task values\n",
    "        task_out = PowerTransformer().fit_transform(task_out.values.reshape(-1,1))\n",
    "        data_results = data_results.drop([task], axis=1)\n",
    "        data_index = [data_results.columns[ii][:data_results.columns[ii].find('_')] for ii in range(len(data_results.columns))]\n",
    "        # Scale data\n",
    "        data_ = PowerTransformer().fit_transform(data_results.values)\n",
    "        pca_ = PCA(n_components=min(data_.shape))\n",
    "        # Fit PCA\n",
    "        pca_.fit(data_)\n",
    "        \n",
    "        # explained variance\n",
    "        exp_variance = pd.DataFrame(pca_.explained_variance_ratio_, index=1 + np.arange(min(data_.shape)), columns=['explained variance'])\n",
    "        # create df\n",
    "        save_pca = pd.DataFrame(data=pca_.components_, index=1 + np.arange(min(data_.shape)), columns=data_index)\n",
    "        save_pca = pd.concat([save_pca, exp_variance], axis=1)\n",
    "        save_pca.to_csv(os.path.join(results_8_dir, '8_' + task + '_' + idgroup + '_pca_results_sp.csv'))\n",
    "        \n",
    "        # Run principal component regression\n",
    "        # Transform PCA data to obtain individual scores\n",
    "        X_model = pca_.transform(data_)\n",
    "        X_model = pd.DataFrame(data=X_model, index=data_results.index, columns=np.arange(min(data_.shape))+1)\n",
    "        \n",
    "        # put each component in PCR model\n",
    "        adj_r2_models = []\n",
    "        comps_reg = X_model.columns\n",
    "        \n",
    "        # run model each time adding a new component and calculate adjusted R2 using statsmodels\n",
    "        for in_pcr in range(len(comps_reg)):\n",
    "\n",
    "            X_reg = sm.add_constant(X_model[comps_reg[0:in_pcr+1]], prepend='False')\n",
    "            mod = sm.OLS(task_out, X_reg)\n",
    "            res = mod.fit()\n",
    "            adj_r2_models.append(res.rsquared_adj)\n",
    "            \n",
    "        # save PCR results\n",
    "        index_df = ['PC 1-' + str(i+1) for i in range(len(adj_r2_models))]\n",
    "        index_df[0] = 'PC 1'\n",
    "        pcr_results = pd.DataFrame(data=adj_r2_models, columns=['adjusted R-squared'], index=index_df)\n",
    "        pcr_results.to_csv(os.path.join(results_8_dir, '8_PCR_' + task + '_' + idgroup + '_sp.csv'))\n",
    "    \n",
    "    data_results = []\n",
    "    \n",
    "    if n_feats_dc > 1:\n",
    "        \n",
    "        str_corr_dc = list(filter(lambda x: '1_variables_eeg_' + task + '_' + dc_data in x, files_1))\n",
    "        data_results = pd.read_csv(os.path.join(results_1_dir, str_corr_dc[0]), index_col=0)\n",
    "        task_out = data_results[task]\n",
    "        task_out = PowerTransformer().fit_transform(task_out.values.reshape(-1,1))\n",
    "        data_results = data_results.drop([task], axis=1)\n",
    "        data_index = [data_results.columns[ii][:data_results.columns[ii].find('_')] for ii in range(len(data_results.columns))]\n",
    "        data_ = PowerTransformer().fit_transform(data_results.values)\n",
    "        pca_ = PCA(n_components=min(data_.shape))\n",
    "        pca_.fit(data_)\n",
    "        # explained variance\n",
    "        exp_variance = pd.DataFrame(pca_.explained_variance_ratio_, index=1 + np.arange(min(data_.shape)), columns=['explained variance'])\n",
    "        # create df\n",
    "        save_pca = pd.DataFrame(data=pca_.components_, index=1 + np.arange(len(data_index)), columns=data_index)\n",
    "        save_pca = pd.concat([save_pca, exp_variance], axis=1)\n",
    "        save_pca.to_csv(os.path.join(results_8_dir, '8_' + task + '_' + idgroup + '_pca_results_dc.csv'))\n",
    "        \n",
    "        # Run principal component regression\n",
    "        # Transform data to obtain individual scores\n",
    "        X_model = pca_.transform(data_)\n",
    "        X_model = pd.DataFrame(data=X_model, index=data_results.index, columns=np.arange(min(data_.shape))+1)\n",
    "        \n",
    "        # put each component in PCR model\n",
    "        adj_r2_models = []\n",
    "        comps_reg = X_model.columns\n",
    "        \n",
    "        # run model each time adding a new component and calculate adjusted R2 using statsmodels\n",
    "        for in_pcr in range(len(comps_reg)):\n",
    "\n",
    "            X_reg = sm.add_constant(X_model[comps_reg[0:in_pcr+1]], prepend='False')\n",
    "            mod = sm.OLS(task_out, X_reg)\n",
    "            res = mod.fit()\n",
    "            adj_r2_models.append(res.rsquared_adj)\n",
    "            \n",
    "        # save PCR results\n",
    "        index_df = ['PC 1-' + str(i+1) for i in range(len(adj_r2_models))]\n",
    "        index_df[0] = 'PC 1'\n",
    "        pcr_results = pd.DataFrame(data=adj_r2_models, columns=['adjusted R-squared'], index=index_df)\n",
    "        pcr_results.to_csv(os.path.join(results_8_dir, '8_PCR_' + task + '_' + idgroup + '_dc.csv'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c97ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For features showing group differences\n",
    "\n",
    "if idgroup == 'y':\n",
    "    data_group = pd.read_csv(os.path.join(results_4_dir, '4_variables_eeg_y.csv'), index_col=0)\n",
    "else:\n",
    "    data_group = pd.read_csv(os.path.join(results_4_dir, '4_variables_eeg_o.csv'), index_col=0)\n",
    "        \n",
    "\n",
    "# PCA\n",
    "data_ = VarianceThreshold().fit_transform(data_group.values)\n",
    "data_ = PowerTransformer().fit_transform(data_)\n",
    "pca_group = PCA(n_components=min(data_group.shape))\n",
    "pca_group.fit(data_)\n",
    "# explained variance\n",
    "exp_variance = pd.DataFrame(pca_group.explained_variance_ratio_, index=1 + np.arange(min(data_group.shape)), columns=['explained variance'])\n",
    "# concatenate DataFrame\n",
    "save_pca = pd.DataFrame(data=pca_group.components_, index=1 + np.arange(min(data_group.shape)), columns=data_group.columns)\n",
    "save_pca = pd.concat([save_pca, exp_variance], axis=1)\n",
    "save_pca.to_csv(os.path.join(results_8_dir, '8_group_difference' + '_' + idgroup + '_pca_results_sp.csv'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stats_eeg]",
   "language": "python",
   "name": "conda-env-stats_eeg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
