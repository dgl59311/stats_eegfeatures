{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Summarize results \n",
    "\n",
    "- In this script we summarize the results of the analyses and generate some .csv files with the main outcomes\n",
    "- Here we show the data that are presented in the main text of the manuscript\n",
    "\n",
    "Gordillo, da Cruz, Moreno, Garobbio, Herzog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = os.getcwd()\n",
    "np.random.seed(234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of younger participants =  138\n",
      "Number of females =  42\n",
      "Mean age =  25.43\n",
      "Std age =  3.39\n",
      "Older participants\n",
      "Number of older participants =  63\n",
      "Number of females =  31\n",
      "Mean age =  67.66\n",
      "Std age =  4.79\n"
     ]
    }
   ],
   "source": [
    "# Demographical data\n",
    "demog_data = pd.read_csv(os.path.join(main_dir, 'data', 'age_bins_values.csv'), index_col=0)\n",
    "print('Number of younger participants = ', len(np.where(demog_data['Group'] == 1)[0]))\n",
    "print('Number of females = ', len(np.where(demog_data.iloc[np.where(demog_data['Group'] == 1)[0]]['Gender'] == 1)[0]))\n",
    "print('Mean age = ', np.round(np.mean(demog_data.iloc[np.where(demog_data['Group'] == 1)[0]]['Age']), 2))\n",
    "print('Std age = ', np.round(np.std(demog_data.iloc[np.where(demog_data['Group'] == 1)[0]]['Age']), 2))\n",
    "print('Older participants')\n",
    "print('Number of older participants = ', len(np.where(demog_data['Group'] == 2)[0]))\n",
    "print('Number of females = ', len(np.where(demog_data.iloc[np.where(demog_data['Group'] == 2)[0]]['Gender'] == 1)[0]))\n",
    "print('Mean age = ', np.round(np.mean(demog_data.iloc[np.where(demog_data['Group'] == 2)[0]]['Age']), 2))\n",
    "print('Std age = ', np.round(np.std(demog_data.iloc[np.where(demog_data['Group'] == 2)[0]]['Age']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories of results\n",
    "data_dir = os.path.join(main_dir, 'data')\n",
    "results_dir = os.path.join(main_dir, 'results')\n",
    "results_1_dir = os.path.join(results_dir, '1_correlations_eeg_beh_results')\n",
    "results_2_dir = os.path.join(results_dir, '2_regression_results')\n",
    "results_3_dir = os.path.join(results_dir, '3_group_comparison_results')\n",
    "results_4_dir = os.path.join(results_dir, '4_correlations_groups_results')\n",
    "results_5_dir = os.path.join(results_dir, '5_distancecorrelation_results')\n",
    "results_6_dir = os.path.join(results_dir, '6_correlations_references_results')\n",
    "results_7_dir = os.path.join(results_dir, '7_icc_references_results')\n",
    "results_8_dir = os.path.join(results_dir, '8_pca_results')\n",
    "\n",
    "summary_results_dir = os.path.join(results_dir, 'summary_results')\n",
    "\n",
    "os.chdir(main_dir)\n",
    "\n",
    "# behavior variables\n",
    "\n",
    "beh_vars = [\"Cvlt_attention_span\", \"Cvlt_delayed_memory\", \"Pts-2_subtest_3\",\n",
    "            \"Rwt_animal_categories\", \"Rwt_s_words\", \"Tap_alertness\",\n",
    "            \"Tap_simon_congruent\", \"Tap_simon_incongruent\", \"Tap_working_memory\",\n",
    "            \"Tmt-A\", \"Tmt-B\", \"Vocabulary_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results section: Correlations between EEG features and cognitive variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation analysis\n",
      "N significant analyses using spearman correlation 109.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N significant</th>\n",
       "      <th>min corr</th>\n",
       "      <th>max corr</th>\n",
       "      <th>within eeg 25</th>\n",
       "      <th>within eeg 50</th>\n",
       "      <th>within eeg 75</th>\n",
       "      <th>multivar dc eeg 25</th>\n",
       "      <th>multivar dc eeg 50</th>\n",
       "      <th>multivar dc eeg 75</th>\n",
       "      <th>% significant multivar dc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cvlt_attention_span</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.244167</td>\n",
       "      <td>0.317438</td>\n",
       "      <td>0.379561</td>\n",
       "      <td>0.503581</td>\n",
       "      <td>0.699757</td>\n",
       "      <td>0.445621</td>\n",
       "      <td>0.592408</td>\n",
       "      <td>0.728856</td>\n",
       "      <td>0.994152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cvlt_delayed_memory</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.271669</td>\n",
       "      <td>0.296181</td>\n",
       "      <td>0.088752</td>\n",
       "      <td>0.142166</td>\n",
       "      <td>0.281740</td>\n",
       "      <td>0.118281</td>\n",
       "      <td>0.228204</td>\n",
       "      <td>0.490347</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pts-2_subtest_3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.293511</td>\n",
       "      <td>0.326514</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.139398</td>\n",
       "      <td>0.139398</td>\n",
       "      <td>0.139398</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rwt_animal_categories</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.198816</td>\n",
       "      <td>0.310946</td>\n",
       "      <td>0.060505</td>\n",
       "      <td>0.133215</td>\n",
       "      <td>0.213677</td>\n",
       "      <td>0.081108</td>\n",
       "      <td>0.111019</td>\n",
       "      <td>0.206998</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rwt_s_words</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.260827</td>\n",
       "      <td>0.321291</td>\n",
       "      <td>0.078317</td>\n",
       "      <td>0.669298</td>\n",
       "      <td>0.671439</td>\n",
       "      <td>0.099458</td>\n",
       "      <td>0.644703</td>\n",
       "      <td>0.663306</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tap_alertness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tap_simon_congruent</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.278036</td>\n",
       "      <td>0.325477</td>\n",
       "      <td>0.132823</td>\n",
       "      <td>0.238867</td>\n",
       "      <td>0.339070</td>\n",
       "      <td>0.105166</td>\n",
       "      <td>0.201492</td>\n",
       "      <td>0.393799</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tap_simon_incongruent</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.263934</td>\n",
       "      <td>0.367323</td>\n",
       "      <td>0.311264</td>\n",
       "      <td>0.381934</td>\n",
       "      <td>0.591086</td>\n",
       "      <td>0.182359</td>\n",
       "      <td>0.516523</td>\n",
       "      <td>0.620004</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tap_working_memory</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.249328</td>\n",
       "      <td>0.329861</td>\n",
       "      <td>0.118056</td>\n",
       "      <td>0.237552</td>\n",
       "      <td>0.349915</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>0.225993</td>\n",
       "      <td>0.339585</td>\n",
       "      <td>0.830065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tmt-A</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.257787</td>\n",
       "      <td>0.326931</td>\n",
       "      <td>0.086024</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>0.336486</td>\n",
       "      <td>0.111224</td>\n",
       "      <td>0.185139</td>\n",
       "      <td>0.369926</td>\n",
       "      <td>0.649123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tmt-B</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.288506</td>\n",
       "      <td>0.342601</td>\n",
       "      <td>0.151506</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.434938</td>\n",
       "      <td>0.084253</td>\n",
       "      <td>0.443078</td>\n",
       "      <td>0.646225</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vocabulary_test</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.281881</td>\n",
       "      <td>0.307579</td>\n",
       "      <td>0.091530</td>\n",
       "      <td>0.119919</td>\n",
       "      <td>0.186225</td>\n",
       "      <td>0.095479</td>\n",
       "      <td>0.126449</td>\n",
       "      <td>0.198858</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       N significant  min corr  max corr  within eeg 25  \\\n",
       "Cvlt_attention_span             19.0  0.244167  0.317438       0.379561   \n",
       "Cvlt_delayed_memory              7.0  0.271669  0.296181       0.088752   \n",
       "Pts-2_subtest_3                  2.0  0.293511  0.326514       0.052966   \n",
       "Rwt_animal_categories            7.0  0.198816  0.310946       0.060505   \n",
       "Rwt_s_words                      8.0  0.260827  0.321291       0.078317   \n",
       "Tap_alertness                    0.0  0.000000  0.000000       0.000000   \n",
       "Tap_simon_congruent              7.0  0.278036  0.325477       0.132823   \n",
       "Tap_simon_incongruent            6.0  0.263934  0.367323       0.311264   \n",
       "Tap_working_memory              18.0  0.249328  0.329861       0.118056   \n",
       "Tmt-A                           19.0  0.257787  0.326931       0.086024   \n",
       "Tmt-B                           11.0  0.288506  0.342601       0.151506   \n",
       "Vocabulary_test                  5.0  0.281881  0.307579       0.091530   \n",
       "\n",
       "                       within eeg 50  within eeg 75  multivar dc eeg 25  \\\n",
       "Cvlt_attention_span         0.503581       0.699757            0.445621   \n",
       "Cvlt_delayed_memory         0.142166       0.281740            0.118281   \n",
       "Pts-2_subtest_3             0.052966       0.052966            0.139398   \n",
       "Rwt_animal_categories       0.133215       0.213677            0.081108   \n",
       "Rwt_s_words                 0.669298       0.671439            0.099458   \n",
       "Tap_alertness               0.000000       0.000000            0.000000   \n",
       "Tap_simon_congruent         0.238867       0.339070            0.105166   \n",
       "Tap_simon_incongruent       0.381934       0.591086            0.182359   \n",
       "Tap_working_memory          0.237552       0.349915            0.148305   \n",
       "Tmt-A                       0.175520       0.336486            0.111224   \n",
       "Tmt-B                       0.268657       0.434938            0.084253   \n",
       "Vocabulary_test             0.119919       0.186225            0.095479   \n",
       "\n",
       "                       multivar dc eeg 50  multivar dc eeg 75  \\\n",
       "Cvlt_attention_span              0.592408            0.728856   \n",
       "Cvlt_delayed_memory              0.228204            0.490347   \n",
       "Pts-2_subtest_3                  0.139398            0.139398   \n",
       "Rwt_animal_categories            0.111019            0.206998   \n",
       "Rwt_s_words                      0.644703            0.663306   \n",
       "Tap_alertness                    0.000000            0.000000   \n",
       "Tap_simon_congruent              0.201492            0.393799   \n",
       "Tap_simon_incongruent            0.516523            0.620004   \n",
       "Tap_working_memory               0.225993            0.339585   \n",
       "Tmt-A                            0.185139            0.369926   \n",
       "Tmt-B                            0.443078            0.646225   \n",
       "Vocabulary_test                  0.126449            0.198858   \n",
       "\n",
       "                       % significant multivar dc  \n",
       "Cvlt_attention_span                     0.994152  \n",
       "Cvlt_delayed_memory                     0.714286  \n",
       "Pts-2_subtest_3                         1.000000  \n",
       "Rwt_animal_categories                   0.476190  \n",
       "Rwt_s_words                             0.535714  \n",
       "Tap_alertness                           0.000000  \n",
       "Tap_simon_congruent                     0.619048  \n",
       "Tap_simon_incongruent                   0.933333  \n",
       "Tap_working_memory                      0.830065  \n",
       "Tmt-A                                   0.649123  \n",
       "Tmt-B                                   0.600000  \n",
       "Vocabulary_test                         0.400000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read files in the correct folder\n",
    "files_1 = os.listdir(results_1_dir)\n",
    "\n",
    "# Names of the columns for the summary file\n",
    "results_1_cols = ['N significant', 'min corr', 'max corr', \n",
    "                  'within eeg 25', 'within eeg 50', 'within eeg 75',\n",
    "                  'multivar dc eeg 25', 'multivar dc eeg 50', 'multivar dc eeg 75','% significant multivar dc']\n",
    "\n",
    "# Summarize results for:\n",
    "idgroup = 'y'\n",
    "\n",
    "sp_data = 'spearman_' + idgroup\n",
    "dc_data = 'distcorr_' + idgroup\n",
    "\n",
    "data_mask_sp = pd.read_csv(os.path.join(results_1_dir,'1_mask_' + sp_data + '.csv'), index_col=0)\n",
    "data_mask_dc = pd.read_csv(os.path.join(results_1_dir,'1_mask_' + dc_data + '.csv'), index_col=0)\n",
    "spearman_max = pd.read_csv(os.path.join(results_1_dir,'1_maxcorrvals_' + sp_data +'.csv'), index_col=0)\n",
    "distcorr_max = pd.read_csv(os.path.join(results_1_dir,'1_maxcorrvals_' + dc_data +'.csv'), index_col=0)\n",
    "multivardc = pd.read_csv(os.path.join(results_5_dir,'5_dc_fx_'+ idgroup +'.csv'), index_col=0)\n",
    "multivardc_pvals = pd.read_csv(os.path.join(results_5_dir,'5_dc_pval_'+ idgroup +'.csv'), index_col=0)\n",
    "\n",
    "results_sp = np.zeros((len(beh_vars), len(results_1_cols)))\n",
    "results_dc = np.zeros((len(beh_vars), len(results_1_cols)))\n",
    "\n",
    "for k in range(len(beh_vars)):\n",
    "    \n",
    "    task = beh_vars[k]\n",
    "    \n",
    "    vec_mask_sp = data_mask_sp[task].loc[data_mask_sp[task]!='NS']\n",
    "    n_feats_sp = len(vec_mask_sp)\n",
    "    \n",
    "    vec_mask_dc = data_mask_dc[task].loc[data_mask_dc[task]!='NS']\n",
    "    n_feats_dc = len(vec_mask_dc)\n",
    "    \n",
    "    if n_feats_sp > 1:\n",
    "        \n",
    "        str_corr_sp = list(filter(lambda x: '1_correlations_eeg_' + task + '_' + sp_data in x, files_1))\n",
    "        data_results = pd.read_csv(os.path.join(results_1_dir, str_corr_sp[0]), index_col=0)      \n",
    "        min_sp = np.min(np.abs(np.diag(data_results.values)))\n",
    "        max_sp = np.max(np.abs(np.diag(data_results.values)))\n",
    "        sp_within = np.percentile(np.abs(data_results.values[np.triu_indices(n_feats_sp,1)]), (25, 50, 75))\n",
    "        \n",
    "        # find multivariate distance correlation values between pairs of EEG features \n",
    "        ix = vec_mask_sp.index\n",
    "        feats = list(itertools.combinations(ix, 2))\n",
    "        feats = list(set(feats))\n",
    "        multivardc_vals = [multivardc[feats[i][1]][feats[i][0]] for i in range(len(feats))]\n",
    "        # get the sqrt of multivariate dc since it approximates the population squared distance correlation      \n",
    "        multivardc_within = np.percentile(np.sqrt(np.abs(multivardc_vals)), (25, 50, 75))\n",
    "        \n",
    "        multivardc_p = [multivardc_pvals[feats[i][1]][feats[i][0]] for i in range(len(feats))]\n",
    "        prop_multi_sig = len(np.where(np.array(multivardc_p) < 0.05)[0])/len(multivardc_p)\n",
    "        task_results = np.hstack([n_feats_sp, min_sp, max_sp, sp_within, multivardc_within, prop_multi_sig])\n",
    "        \n",
    "    elif n_feats_sp == 1:\n",
    "        \n",
    "        corr_val = np.abs(spearman_max[task][vec_mask_sp.index[0]])\n",
    "        task_results = np.hstack([n_feats_sp, 0, corr_val, np.zeros(7)])\n",
    "    \n",
    "    elif n_feats_sp == 0:\n",
    "        \n",
    "        task_results = np.zeros(10)\n",
    "        \n",
    "    results_sp[k, :] = task_results\n",
    "\n",
    "    # for distance correlations\n",
    "    task_results = []\n",
    "    \n",
    "    if n_feats_dc > 1:\n",
    "        \n",
    "        str_corr_dc = list(filter(lambda x: '1_correlations_eeg_' + task + '_' + dc_data in x, files_1))\n",
    "        data_results = pd.read_csv(os.path.join(results_1_dir, str_corr_dc[0]), index_col=0)      \n",
    "        min_dc = np.min(np.abs(np.diag(data_results.values)))\n",
    "        max_dc = np.max(np.abs(np.diag(data_results.values)))\n",
    "        dc_within = np.percentile(np.abs(data_results.values[np.triu_indices(n_feats_dc,1)]), (25, 50, 75))\n",
    "        \n",
    "        # find multivariate distance correlation values between pairs of EEG features \n",
    "        ix = vec_mask_dc.index\n",
    "        feats = list(itertools.combinations(ix, 2))\n",
    "        feats = list(set(feats))\n",
    "        multivardc_vals = [multivardc[feats[i][1]][feats[i][0]] for i in range(len(feats))]\n",
    "        # get the sqrt of multivariate dc since it approximates the population squared distance correlation     \n",
    "        multivardc_within = np.percentile(np.sqrt(np.abs(multivardc_vals)), (25, 50, 75))\n",
    "        multivardc_p = [multivardc_pvals[feats[i][1]][feats[i][0]] for i in range(len(feats))]\n",
    "        prop_multi_sig = len(np.where(np.array(multivardc_p) < 0.05)[0])/len(multivardc_p)\n",
    "        task_results = np.hstack([n_feats_dc, min_dc, max_dc, dc_within, multivardc_within, prop_multi_sig])\n",
    "        \n",
    "    elif n_feats_dc == 1:\n",
    "        \n",
    "        corr_val = np.abs(distcorr_max[task][vec_mask_dc.index[0]])\n",
    "        task_results = np.hstack([n_feats_dc, 0, corr_val, np.zeros(7)])\n",
    "    \n",
    "    elif n_feats_dc == 0:\n",
    "        \n",
    "        task_results = np.zeros(10)\n",
    "    \n",
    "    results_dc[k, :] = task_results\n",
    "\n",
    "# save data\n",
    "# spearman \n",
    "summary_spearman = pd.DataFrame(data=results_sp, index=beh_vars,\n",
    "                                columns=results_1_cols)\n",
    "summary_spearman.to_csv(os.path.join(summary_results_dir, '1_summary_spearman_' + idgroup + '.csv'))     \n",
    "\n",
    "# distcorr\n",
    "summary_distcorr = pd.DataFrame(data=results_dc, index=beh_vars,\n",
    "                                columns=results_1_cols)\n",
    "summary_distcorr.to_csv(os.path.join(summary_results_dir, '1_summary_distcorr_' + idgroup + '.csv'))  \n",
    "\n",
    "print('Spearman correlation analysis')\n",
    "print('N significant analyses using spearman correlation',sum(summary_spearman['N significant']))\n",
    "summary_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance correlation analysis\n",
      "N significant analyses using distance correlation 121.0\n"
     ]
    }
   ],
   "source": [
    "print('Distance correlation analysis')\n",
    "#print(summary_distcorr)\n",
    "print('N significant analyses using distance correlation', sum(summary_distcorr['N significant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microstate B has a correlation of:  0.27 to  Rwt_animal_categories\n",
      "clust coef e-wpli alpha has a correlation of:  0.28 to  Rwt_animal_categories\n",
      "microstate B  and  clust coef e-wpli alpha have a correlation of:  0.41\n",
      "microstate B  and  clust coef e-wpli alpha have a multivar correlation of:  0.35\n"
     ]
    }
   ],
   "source": [
    "# Examples \n",
    "task = 'Rwt_animal_categories'\n",
    "eeg_feature_1 = 'microstate B'\n",
    "eeg_feature_2 = 'clust coef e-wpli alpha'\n",
    "corr_type = 'distcorr_'\n",
    "idgroup = 'y'\n",
    "\n",
    "# Find Spearman correlations\n",
    "str_corr_ = list(filter(lambda x: '1_correlations_eeg_' + task + '_' + corr_type + idgroup in x, files_1))\n",
    "data_results = pd.read_csv(os.path.join(results_1_dir, str_corr_[0]), index_col=0)   \n",
    "\n",
    "index_1 = list(data_results).index(eeg_feature_1)\n",
    "index_2 = list(data_results).index(eeg_feature_2)\n",
    "\n",
    "# Find multivariate distance correlations between two EEG features\n",
    "multivardc = pd.read_csv(os.path.join(results_5_dir,'5_dc_fx_'+ idgroup +'.csv'), index_col=0)\n",
    "dc_ = np.sqrt(np.abs(multivardc[eeg_feature_2][eeg_feature_1]))\n",
    "if dc_ == 0:\n",
    "    dc_ = np.sqrt(np.abs(multivardc[eeg_feature_1][eeg_feature_2]))\n",
    "    \n",
    "print(eeg_feature_1, 'has a correlation of: ', np.round(data_results.iloc[index_1, index_1], 2), 'to ', task,)\n",
    "print(eeg_feature_2, 'has a correlation of: ', np.round(data_results.iloc[index_2, index_2], 2), 'to ', task,)\n",
    "print(eeg_feature_1, ' and ', eeg_feature_2, 'have a correlation of: ', np.round(data_results.iloc[index_1, index_2], 2))\n",
    "print(eeg_feature_1, ' and ', eeg_feature_2, 'have a multivar correlation of: ', np.round(dc_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering variables showing a significant distance correlation\n",
      "Rwt_s_words correlated with 9 EEG features\n",
      "1st PC in  Rwt_s_words explains:  58.64 %\n",
      "First three PCs in  Rwt_s_words explain 85.956 %\n",
      "\n",
      "General summary\n",
      "For results using Spearman correlation\n",
      "min-max-median variance explained by 1st PC across tasks [29.324, 62.834, 44.15]\n",
      "min-max-median variance explained by 1-3 PCs across tasks [48.658, 100.0, 79.247]\n",
      "\n",
      "For results using distance correlation\n",
      "min-max-median variance explained by 1st PC across tasks [27.807, 58.64, 33.897999999999996]\n",
      "min-max-median variance explained by 1-3 PCs across tasks [52.133, 100.0, 72.2105]\n",
      "\n",
      "For features showing group differences\n",
      "First component explains 24.01177581173413 % of 108 EEG features\n",
      "Second component explains 13.47155760568583 % of 108 EEG features\n",
      "Third component explains 7.5431528351615 % of 108 EEG features\n",
      "First 3 components explains 45.026 % of 63 EEG features\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "idgroup = 'y'\n",
    "files_summ = os.listdir(results_8_dir)\n",
    "\n",
    "# PCA results\n",
    "var_exp_sp = []\n",
    "var_exp_sp_comp = []\n",
    "\n",
    "var_exp_dc = []\n",
    "var_exp_dc_comp = []\n",
    "\n",
    "beh_vars = [\"Cvlt_attention_span\", \"Cvlt_delayed_memory\", \"Pts-2_subtest_3\",\n",
    "            \"Rwt_animal_categories\", \"Rwt_s_words\", \"Tap_alertness\",\n",
    "            \"Tap_simon_congruent\", \"Tap_simon_incongruent\", \"Tap_working_memory\",\n",
    "            \"Tmt-A\", \"Tmt-B\", \"Vocabulary_test\"]\n",
    "\n",
    "# Display results for\n",
    "print_for = 'Rwt_s_words'\n",
    "corr_type = 'distcorr'\n",
    "\n",
    "for k in range(len(beh_vars)):\n",
    "    \n",
    "    task = beh_vars[k]\n",
    "    \n",
    "    # For spearman rho\n",
    "    str_corr_sp = list(filter(lambda x: '8_' + task + '_' + idgroup + '_pca_results_sp' in x, files_summ))\n",
    "    \n",
    "    # For distance correlation\n",
    "    str_corr_dc = list(filter(lambda x: '8_' + task + '_' + idgroup + '_pca_results_dc' in x, files_summ))\n",
    "    \n",
    "    if len(str_corr_sp) > 0:\n",
    "        \n",
    "        data_results = pd.read_csv(os.path.join(results_8_dir, str_corr_sp[0]), index_col=0)    \n",
    "        pc1_ev = np.round(data_results['explained variance'].iloc[0]*100, 3)\n",
    "        pc1_3_ev = np.round(data_results['explained variance'].iloc[0:3].sum()*100, 3)\n",
    "        \n",
    "        if corr_type == 'spearman' and print_for == task:\n",
    "        \n",
    "            print('Considering variables showing a significant Spearman correlation')\n",
    "            print(task, 'correlated with', data_results.shape[0], 'EEG features')\n",
    "            print('1st PC in ', task, 'explains: ', pc1_ev, '%')\n",
    "            print('First three PCs in ', task, 'explain', pc1_3_ev,'%')\n",
    "            print()\n",
    "        \n",
    "        var_exp_sp.append(pc1_ev)\n",
    "        var_exp_sp_comp.append(pc1_3_ev)\n",
    "    \n",
    "    if len(str_corr_dc) > 0:\n",
    "        \n",
    "        data_results = pd.read_csv(os.path.join(results_8_dir, str_corr_dc[0]), index_col=0)   \n",
    "        pc1_ev = np.round(data_results['explained variance'].iloc[0]*100, 3)\n",
    "        pc1_3_ev = np.round(data_results['explained variance'].iloc[0:3].sum()*100, 3)\n",
    "        \n",
    "        if corr_type == 'distcorr' and print_for == task:\n",
    "        \n",
    "            print('Considering variables showing a significant distance correlation')\n",
    "            print(task, 'correlated with', data_results.shape[0], 'EEG features')\n",
    "            print('1st PC in ', task, 'explains: ', pc1_ev, '%')\n",
    "            print('First three PCs in ', task, 'explain', pc1_3_ev,'%')\n",
    "            print()\n",
    "        \n",
    "        var_exp_dc.append(pc1_ev)\n",
    "        var_exp_dc_comp.append(pc1_3_ev)\n",
    "        \n",
    "        \n",
    "print('General summary')    \n",
    "print('For results using Spearman correlation')\n",
    "print('min-max-median variance explained by 1st PC across tasks', [min(var_exp_sp), max(var_exp_sp), np.median(var_exp_sp)])\n",
    "print('min-max-median variance explained by 1-3 PCs across tasks', [min(var_exp_sp_comp), max(var_exp_sp_comp), np.median(var_exp_sp_comp)])\n",
    "print()\n",
    "print('For results using distance correlation')\n",
    "print('min-max-median variance explained by 1st PC across tasks', [min(var_exp_dc), max(var_exp_dc), np.median(var_exp_dc)])\n",
    "print('min-max-median variance explained by 1-3 PCs across tasks', [min(var_exp_dc_comp), max(var_exp_dc_comp), np.median(var_exp_dc_comp)])\n",
    "\n",
    "# For features showing group differences\n",
    "\n",
    "idgroup_c = 'o'\n",
    "group_comp = pd.read_csv(os.path.join(results_8_dir, '8_group_difference_'+ idgroup_c +'_pca_results_sp.csv'), index_col=0)\n",
    "print()   \n",
    "print('For features showing group differences')   \n",
    "print('First component explains', group_comp['explained variance'].values[0]*100 , '% of', group_comp.shape[1]-1, 'EEG features')\n",
    "print('Second component explains', group_comp['explained variance'].values[1]*100 , '% of', group_comp.shape[1]-1, 'EEG features')\n",
    "print('Third component explains', group_comp['explained variance'].values[2]*100 , '% of', group_comp.shape[1]-1, 'EEG features')\n",
    "print('First 3 components explains', np.sum(group_comp['explained variance'].values[0:3]*100).round(3) , '% of', group_comp.shape[0], 'EEG features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R2 values using principal components to predict cognitive tasks\n",
      "\n",
      "Using variables showing significant distance correlation\n",
      "11   EEG features showed significant distance correlations to  Rwt_animal_categories\n",
      "Rwt_animal_categories:  PC 1  :   0.114\n",
      "Rwt_animal_categories:  PC 1-3:   0.223\n",
      "\n",
      "General summary\n",
      "Min adj-R2 for EEG features showing Spearman correlation, 1PC:  -0.0073125153717175\n",
      "Max adj-R2 for EEG features showing Spearman correlation, 1PC:  0.2163688892280325\n",
      "Median adj-R2 for EEG features showing Spearman correlation, 1PC:  0.145938852567184\n",
      "\n",
      "Min adj-R2 for EEG features showing Spearman correlation, 1-3PC:  0.1068880670494067\n",
      "Max adj-R2 for EEG features showing Spearman correlation, 1-3PC:  0.322047433330785\n",
      "Median adj-R2 for EEG features showing Spearman correlation, 1-3PC:  0.2056124421986235\n",
      "\n",
      "Min adj-R2 for EEG features showing distance correlation, 1PC:  0.0662891438366922\n",
      "Max adj-R2 for EEG features showing distance correlation, 1PC:  0.2024072814780065\n",
      "Median adj-R2 for EEG features showing distance correlation, 1PC:  0.11592799137603045\n",
      "\n",
      "Min adj-R2 for EEG features showing distance correlation, 1-3PC:  0.0949696118153372\n",
      "Max adj-R2 for EEG features showing distance correlation, 1-3PC:  0.2234140764287865\n",
      "Median adj-R2 for EEG features showing distance correlation, 1-3PC:  0.14212307320976605\n"
     ]
    }
   ],
   "source": [
    "# Results from multiple regression\n",
    "\n",
    "idgroup = 'y'\n",
    "\n",
    "# Save adj R2 values\n",
    "pc1_adj_sp = []\n",
    "pc1_3_adj_sp = []\n",
    "\n",
    "pc1_adj_dc = []\n",
    "pc1_3_adj_dc = []\n",
    "\n",
    "# concatenate dataframes\n",
    "df_sp = []\n",
    "df_sp_task = []\n",
    "df_dc = []\n",
    "df_dc_task = []\n",
    "\n",
    "# Display results for\n",
    "print_for = 'Rwt_animal_categories'\n",
    "corr_type = 'distcorr'\n",
    "\n",
    "\n",
    "print('Adjusted R2 values using principal components to predict cognitive tasks')\n",
    "print()\n",
    "\n",
    "for k in range(len(beh_vars)):\n",
    "    \n",
    "    task = beh_vars[k]\n",
    "    # Results using Spearman correlations\n",
    "    str_pcr_sp = list(filter(lambda x: '8_PCR_' + task + '_' + idgroup + '_sp' in x, files_summ))\n",
    "    # Results using distance correlations\n",
    "    str_pcr_dc = list(filter(lambda x: '8_PCR_' + task + '_' + idgroup + '_dc' in x, files_summ))\n",
    "\n",
    "    if len(str_pcr_sp) > 0:\n",
    "        \n",
    "        # Spearman\n",
    "        data_results = pd.read_csv(os.path.join(results_8_dir, str_pcr_sp[0]), index_col = 0)    \n",
    "        \n",
    "        pc1_pred = data_results['adjusted R-squared'].loc['PC 1']\n",
    "        pc1_adj_sp.append(pc1_pred)\n",
    "        \n",
    "        if data_results.shape[0] > 2:\n",
    "            pc1_3_pred = data_results['adjusted R-squared'].loc['PC 1-3']\n",
    "        else: \n",
    "            pc1_3_pred = data_results['adjusted R-squared'].loc['PC 1-2']\n",
    "            \n",
    "        pc1_3_adj_sp.append(pc1_3_pred)\n",
    "        df_sp.append(data_results)\n",
    "        df_sp_task.append(task)\n",
    "        \n",
    "        if corr_type=='spearman' and print_for == task:\n",
    "            \n",
    "            print('Using variables showing significant Spearman correlation')\n",
    "            print(len(data_results), '  EEG features showed significant Spearman correlations to ', task)\n",
    "            print(task + ':  PC 1  :  ', pc1_pred.round(3))\n",
    "        \n",
    "            if data_results.shape[0] > 2:\n",
    "                print(task + ':  PC 1-3:  ', pc1_3_pred.round(3))\n",
    "            else:\n",
    "                print(task + ':  PC 1-2:  ', pc1_3_pred.round(3))  \n",
    "        \n",
    "    if len(str_pcr_dc) > 0:\n",
    "        \n",
    "        # Distance correlation\n",
    "        data_results_dc = pd.read_csv(os.path.join(results_8_dir, str_pcr_dc[0]), index_col = 0)    \n",
    "        pc1_pred = data_results_dc['adjusted R-squared'].loc['PC 1']\n",
    "        pc1_adj_dc.append(pc1_pred)\n",
    "        \n",
    "        if data_results_dc.shape[0] > 2:\n",
    "            pc1_3_pred = data_results_dc['adjusted R-squared'].loc['PC 1-3']\n",
    "        else: \n",
    "            pc1_3_pred = data_results_dc['adjusted R-squared'].loc['PC 1-2']\n",
    "        \n",
    "        pc1_3_adj_dc.append(pc1_3_pred)\n",
    "        df_dc.append(data_results_dc)\n",
    "        df_dc_task.append(task)\n",
    "        \n",
    "        if corr_type=='distcorr' and print_for == task:\n",
    "            \n",
    "            print('Using variables showing significant distance correlation')\n",
    "            print(len(data_results_dc), '  EEG features showed significant distance correlations to ', task)\n",
    "            print(task + ':  PC 1  :  ', pc1_pred.round(3))\n",
    "        \n",
    "            if data_results_dc.shape[0] > 2:\n",
    "                print(task + ':  PC 1-3:  ', pc1_3_pred.round(3))\n",
    "            else:\n",
    "                print(task + ':  PC 1-2:  ', pc1_3_pred.round(3))  \n",
    "\n",
    "print()\n",
    "print('General summary')\n",
    "print('Min adj-R2 for EEG features showing Spearman correlation, 1PC: ', np.min(pc1_adj_sp))\n",
    "print('Max adj-R2 for EEG features showing Spearman correlation, 1PC: ', np.max(pc1_adj_sp))\n",
    "print('Median adj-R2 for EEG features showing Spearman correlation, 1PC: ', np.median(pc1_adj_sp))\n",
    "print()\n",
    "print('Min adj-R2 for EEG features showing Spearman correlation, 1-3PC: ', np.min(pc1_3_adj_sp))\n",
    "print('Max adj-R2 for EEG features showing Spearman correlation, 1-3PC: ', np.max(pc1_3_adj_sp))\n",
    "print('Median adj-R2 for EEG features showing Spearman correlation, 1-3PC: ', np.median(pc1_3_adj_sp))\n",
    "print()\n",
    "print('Min adj-R2 for EEG features showing distance correlation, 1PC: ', np.min(pc1_adj_dc))\n",
    "print('Max adj-R2 for EEG features showing distance correlation, 1PC: ', np.max(pc1_adj_dc))\n",
    "print('Median adj-R2 for EEG features showing distance correlation, 1PC: ', np.median(pc1_adj_dc))\n",
    "print()\n",
    "print('Min adj-R2 for EEG features showing distance correlation, 1-3PC: ', np.min(pc1_3_adj_dc))\n",
    "print('Max adj-R2 for EEG features showing distance correlation, 1-3PC: ', np.max(pc1_3_adj_dc))\n",
    "print('Median adj-R2 for EEG features showing distance correlation, 1-3PC: ', np.median(pc1_3_adj_dc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write csv files with PCR summary\n",
    "\n",
    "# For Spearman correlation results\n",
    "sp_results = pd.concat(df_sp, axis=1)\n",
    "df_sp_index = [feature.replace('_', ' ') for feature in df_sp_task]\n",
    "sp_results.columns = df_sp_index\n",
    "sp_results['median'] = sp_results.median(numeric_only=True, axis=1)\n",
    "sp_results = sp_results.round(2)\n",
    "sp_results.to_csv(os.path.join(summary_results_dir, '8_summary_PCR_results_' + idgroup + '_sp.csv'))\n",
    "\n",
    "# For Distance correlation results\n",
    "dc_results = pd.concat(df_dc, axis=1)\n",
    "df_dc_index = [feature.replace('_', ' ') for feature in df_dc_task]\n",
    "dc_results.columns = df_dc_index\n",
    "dc_results['median'] = dc_results.median(numeric_only=True, axis=1)\n",
    "dc_results = dc_results.round(2)\n",
    "dc_results.to_csv(os.path.join(summary_results_dir, '8_summary_PCR_results_' + idgroup + '_dc.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results section: Prediction of cognitive variables using EEG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge models\n",
      "Train set predictive performance (25, 50, 75 percentiles) ridge model for young adults =  [0.00074957 0.00140044 0.02777906]\n",
      "Test set predictive performance (25, 50, 75 percentiles) ridge model for young adults =  [-0.03852588 -0.03015285 -0.02231509]\n",
      "Train set predictive performance (25, 50, 75 percentiles) ridge model for older adults =  [0.00065057 0.00122202 0.06084672]\n",
      "Test set predictive performance (25, 50, 75 percentiles) ridge model for older adults =  [-0.0908049  -0.06295667 -0.03936711]\n",
      "\n",
      "Random forest models\n",
      "Train set predictive performance (25, 50, 75 percentiles) ridge model for young adults =  [0.65395771 0.74086218 0.78276096]\n",
      "Test set predictive performance (25, 50, 75 percentiles) ridge model for young adults =  [-0.13956541 -0.09739039 -0.06499686]\n",
      "Train set predictive performance (25, 50, 75 percentiles) ridge model for older adults =  [0.80246656 0.81578906 0.82763705]\n",
      "Test set predictive performance (25, 50, 75 percentiles) ridge model for older adults =  [-0.24069771 -0.16416614 -0.10220765]\n"
     ]
    }
   ],
   "source": [
    "# Prediction performance \n",
    "# young adults data\n",
    "with open(os.path.join(results_2_dir,'2_regression_y.pkl'), 'rb') as f:\n",
    "    predictive_y = pickle.load(f)\n",
    "# older data\n",
    "with open(os.path.join(results_2_dir,'2_regression_o.pkl'), 'rb') as f:\n",
    "    predictive_o = pickle.load(f)\n",
    "    \n",
    "# ridge results young\n",
    "\n",
    "# train data\n",
    "ridge_train_y = np.percentile(np.concatenate(np.median(predictive_y['ridge_r2_train'], 0)), (25, 50, 75))\n",
    "# create df with median performance\n",
    "ridge_train_df_median = pd.DataFrame(data=np.round(np.median(predictive_y['ridge_r2_train'], 0), 2), index=[k.replace(\".csv\", \"\") for k in predictive_y['eeg features']],\n",
    "                                     columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# create df with iqr values\n",
    "iqr = np.percentile(predictive_y['ridge_r2_train'], 75, 0) - np.percentile(predictive_y['ridge_r2_train'], 25, 0)\n",
    "\n",
    "ridge_train_df_iqr = pd.DataFrame(data=np.round(iqr, 2), index=[k.replace(\".csv\", \"\") for k in predictive_y['eeg features']],\n",
    "                                  columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# merge df\n",
    "ridge_train_df = ridge_train_df_median.astype(str).add(' (').add(ridge_train_df_iqr.astype(str)).add(')')\n",
    "# save df\n",
    "ridge_train_df.to_csv(os.path.join(summary_results_dir, '1_ridge_median_train_y.csv'))    \n",
    "\n",
    "\n",
    "# test data\n",
    "ridge_test_y = np.percentile(np.concatenate(np.median(predictive_y['ridge_r2_test'], 0)), (25, 50, 75))\n",
    "\n",
    "# create df with median performance\n",
    "ridge_test_df_median = pd.DataFrame(data=np.round(np.median(predictive_y['ridge_r2_test'], 0), 2), index=[k.replace(\".csv\", \"\") for k in predictive_y['eeg features']],\n",
    "                                    columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# create df with iqr values\n",
    "iqr = np.percentile(predictive_y['ridge_r2_test'], 75, 0) - np.percentile(predictive_y['ridge_r2_test'], 25, 0)\n",
    "\n",
    "ridge_test_df_iqr = pd.DataFrame(data=np.round(iqr, 2), index=[k.replace(\".csv\", \"\") for k in predictive_y['eeg features']],\n",
    "                                 columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# merge df\n",
    "ridge_test_df = ridge_test_df_median.astype(str).add(' (').add(ridge_test_df_iqr.astype(str)).add(')')\n",
    "# save df\n",
    "ridge_test_df.to_csv(os.path.join(summary_results_dir, '1_ridge_median_test_y.csv'))    \n",
    "\n",
    "\n",
    "# ridge results older\n",
    "\n",
    "# train data\n",
    "ridge_train_o = np.percentile(np.concatenate(np.median(predictive_o['ridge_r2_train'], 0)), (25, 50, 75))\n",
    "\n",
    "# create df with median performance\n",
    "ridge_train_df_median = pd.DataFrame(data=np.round(np.median(predictive_o['ridge_r2_train'], 0), 2), index=[k.replace(\".csv\", \"\") for k in predictive_o['eeg features']],\n",
    "                                     columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# create df with iqr values\n",
    "iqr = np.percentile(predictive_o['ridge_r2_train'], 75, 0) - np.percentile(predictive_o['ridge_r2_train'], 25, 0)\n",
    "\n",
    "ridge_train_df_iqr = pd.DataFrame(data=np.round(iqr, 2), index=[k.replace(\".csv\", \"\") for k in predictive_o['eeg features']],\n",
    "                                  columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# merge df\n",
    "ridge_train_df = ridge_train_df_median.astype(str).add(' (').add(ridge_train_df_iqr.astype(str)).add(')')\n",
    "# save df\n",
    "ridge_train_df.to_csv(os.path.join(summary_results_dir, '1_ridge_median_train_o.csv'))    \n",
    "\n",
    "\n",
    "# test data\n",
    "ridge_test_o = np.percentile(np.concatenate(np.median(predictive_o['ridge_r2_test'], 0)), (25, 50, 75))\n",
    "\n",
    "# create df with median performance\n",
    "ridge_test_df_median = pd.DataFrame(data = np.round(np.median(predictive_o['ridge_r2_test'], 0), 2), index=[k.replace(\".csv\", \"\") for k in predictive_o['eeg features']],\n",
    "                                    columns = [k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# create df with iqr values\n",
    "iqr = np.percentile(predictive_o['ridge_r2_test'], 75, 0) - np.percentile(predictive_o['ridge_r2_test'], 25, 0)\n",
    "\n",
    "ridge_test_df_iqr = pd.DataFrame(data=np.round(iqr, 2), index=[k.replace(\".csv\", \"\") for k in predictive_o['eeg features']],\n",
    "                                 columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# merge df\n",
    "ridge_test_df = ridge_test_df_median.astype(str).add(' (').add(ridge_test_df_iqr.astype(str)).add(')')\n",
    "# save df\n",
    "ridge_test_df.to_csv(os.path.join(summary_results_dir, '1_ridge_median_test_o.csv'))    \n",
    "\n",
    "\n",
    "# Random forest results young\n",
    "\n",
    "# train data\n",
    "rf_train_y = np.percentile(np.concatenate(np.median(predictive_y['rf_r2_train'], 0)), (25, 50, 75))\n",
    "\n",
    "# create df with median performance\n",
    "rf_train_df_median = pd.DataFrame(data = np.round(np.median(predictive_y['rf_r2_train'], 0), 2), index=[k.replace(\".csv\", \"\") for k in predictive_y['eeg features']],\n",
    "                                  columns = [k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# create df with iqr values\n",
    "iqr = np.percentile(predictive_y['rf_r2_train'], 75, 0) - np.percentile(predictive_y['rf_r2_train'], 25, 0)\n",
    "\n",
    "rf_train_df_iqr = pd.DataFrame(data=np.round(iqr, 2), index=[k.replace(\".csv\", \"\") for k in predictive_y['eeg features']],\n",
    "                               columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# merge df\n",
    "rf_train_df = rf_train_df_median.astype(str).add(' (').add(rf_train_df_iqr.astype(str)).add(')')\n",
    "# save df\n",
    "rf_train_df.to_csv(os.path.join(summary_results_dir, '1_rf_median_train_y.csv'))    \n",
    "\n",
    "\n",
    "# test data\n",
    "rf_test_y = np.percentile(np.concatenate(np.median(predictive_y['rf_r2_test'], 0)), (25, 50, 75))\n",
    "\n",
    "# create df with median performance\n",
    "rf_test_df_median = pd.DataFrame(data=np.round(np.median(predictive_y['rf_r2_test'], 0), 2), index=[k.replace(\".csv\", \"\") for k in predictive_y['eeg features']],\n",
    "                                 columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# create df with iqr values\n",
    "iqr = np.percentile(predictive_y['rf_r2_test'], 75, 0) - np.percentile(predictive_y['rf_r2_test'], 25, 0)\n",
    "\n",
    "rf_test_df_iqr = pd.DataFrame(data=np.round(iqr, 2), index=[k.replace(\".csv\", \"\") for k in predictive_y['eeg features']],\n",
    "                              columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# merge df\n",
    "rf_test_df = rf_test_df_median.astype(str).add(' (').add(rf_test_df_iqr.astype(str)).add(')')\n",
    "# save df\n",
    "rf_test_df.to_csv(os.path.join(summary_results_dir, '1_rf_median_test_y.csv'))    \n",
    "\n",
    "# random forest results older\n",
    "\n",
    "# train data\n",
    "rf_train_o = np.percentile(np.concatenate(np.median(predictive_o['rf_r2_train'], 0)), (25, 50, 75))\n",
    "# create df with median performance\n",
    "rf_train_df_median = pd.DataFrame(data=np.round(np.median(predictive_o['rf_r2_train'], 0), 2), index=[k.replace(\".csv\", \"\") for k in predictive_o['eeg features']],\n",
    "                                  columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# create df with iqr values\n",
    "iqr = np.percentile(predictive_o['rf_r2_train'], 75, 0) - np.percentile(predictive_o['rf_r2_train'], 25, 0)\n",
    "\n",
    "rf_train_df_iqr = pd.DataFrame(data=np.round(iqr, 2), index=[k.replace(\".csv\", \"\") for k in predictive_o['eeg features']],\n",
    "                               columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# merge df\n",
    "rf_train_df = rf_train_df_median.astype(str).add(' (').add(rf_train_df_iqr.astype(str)).add(')')\n",
    "# save df\n",
    "rf_train_df.to_csv(os.path.join(summary_results_dir, '1_rf_median_train_o.csv'))    \n",
    "\n",
    "\n",
    "# test data\n",
    "rf_test_o = np.percentile(np.concatenate(np.median(predictive_o['rf_r2_test'], 0)), (25, 50, 75))\n",
    "# create df with median performance\n",
    "rf_test_df_median = pd.DataFrame(data=np.round(np.median(predictive_o['rf_r2_test'], 0), 2), index=[k.replace(\".csv\", \"\") for k in predictive_o['eeg features']],\n",
    "                                 columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# create df with iqr values\n",
    "iqr = np.percentile(predictive_o['rf_r2_test'], 75, 0) - np.percentile(predictive_o['rf_r2_test'], 25, 0)\n",
    "\n",
    "rf_test_df_iqr = pd.DataFrame(data=np.round(iqr, 2), index=[k.replace(\".csv\", \"\") for k in predictive_o['eeg features']],\n",
    "                              columns=[k.replace(\"_\", \" \") for k in beh_vars])\n",
    "# merge df\n",
    "rf_test_df = rf_test_df_median.astype(str).add(' (').add(rf_test_df_iqr.astype(str)).add(')')\n",
    "# save df\n",
    "rf_test_df.to_csv(os.path.join(summary_results_dir, '1_rf_median_test_o.csv'))    \n",
    "\n",
    "\n",
    "print('Ridge models')\n",
    "print('Train set predictive performance (25, 50, 75 percentiles) ridge model for young adults = ', ridge_train_y)\n",
    "print('Test set predictive performance (25, 50, 75 percentiles) ridge model for young adults = ', ridge_test_y)\n",
    "print('Train set predictive performance (25, 50, 75 percentiles) ridge model for older adults = ', ridge_train_o)\n",
    "print('Test set predictive performance (25, 50, 75 percentiles) ridge model for older adults = ', ridge_test_o)\n",
    "print()\n",
    "print('Random forest models')\n",
    "print('Train set predictive performance (25, 50, 75 percentiles) ridge model for young adults = ', rf_train_y)\n",
    "print('Test set predictive performance (25, 50, 75 percentiles) ridge model for young adults = ', rf_test_y)\n",
    "print('Train set predictive performance (25, 50, 75 percentiles) ridge model for older adults = ', rf_train_o)\n",
    "print('Test set predictive performance (25, 50, 75 percentiles) ridge model for older adults = ', rf_test_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results section: Group comparisons of the EEG features between younger and older adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108  EEG features showed significant group differences between young and older adults 0.6171428571428571\n",
      "56  EEG features showed a positive significant effect\n",
      "52  EEG features showed a negative significant effect\n",
      "Mininum significant effect -> Feature :  microstate E , r value :  0.17939923\n",
      "Maximum significant effect -> Feature :  spectral entropy beta , r value :  0.580234883\n",
      "25, 50 and 75 percentles of significant r values:  [0.25904989 0.31288802 0.41526343]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_ch</th>\n",
       "      <th>pvalues</th>\n",
       "      <th>z_stat</th>\n",
       "      <th>r_stat</th>\n",
       "      <th>rcil_stat</th>\n",
       "      <th>rcih_stat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ampl total power alpha.csv</th>\n",
       "      <td>59</td>\n",
       "      <td>4.721086e-02</td>\n",
       "      <td>-3.311934</td>\n",
       "      <td>0.233606</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ampl total power beta.csv</th>\n",
       "      <td>49</td>\n",
       "      <td>4.077954e-03</td>\n",
       "      <td>3.839962</td>\n",
       "      <td>0.270850</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ampl total power delta.csv</th>\n",
       "      <td>5</td>\n",
       "      <td>8.580000e-10</td>\n",
       "      <td>-6.757183</td>\n",
       "      <td>0.476615</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ampl total power gamma.csv</th>\n",
       "      <td>48</td>\n",
       "      <td>4.570000e-07</td>\n",
       "      <td>5.779548</td>\n",
       "      <td>0.407658</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ampl total power theta.csv</th>\n",
       "      <td>59</td>\n",
       "      <td>2.043252e-02</td>\n",
       "      <td>-3.406038</td>\n",
       "      <td>0.240243</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std ampl gamma.csv</th>\n",
       "      <td>48</td>\n",
       "      <td>6.130000e-07</td>\n",
       "      <td>5.729882</td>\n",
       "      <td>0.404155</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std ampl theta.csv</th>\n",
       "      <td>59</td>\n",
       "      <td>3.545612e-02</td>\n",
       "      <td>-3.251813</td>\n",
       "      <td>0.229365</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waiting time beta.csv</th>\n",
       "      <td>49</td>\n",
       "      <td>1.259730e-04</td>\n",
       "      <td>4.660757</td>\n",
       "      <td>0.328744</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waiting time delta.csv</th>\n",
       "      <td>40</td>\n",
       "      <td>3.580000e-06</td>\n",
       "      <td>5.422767</td>\n",
       "      <td>0.382493</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waiting time gamma.csv</th>\n",
       "      <td>55</td>\n",
       "      <td>1.155290e-04</td>\n",
       "      <td>4.673827</td>\n",
       "      <td>0.329666</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            selected_ch       pvalues    z_stat    r_stat  \\\n",
       "features                                                                    \n",
       "ampl total power alpha.csv           59  4.721086e-02 -3.311934  0.233606   \n",
       "ampl total power beta.csv            49  4.077954e-03  3.839962  0.270850   \n",
       "ampl total power delta.csv            5  8.580000e-10 -6.757183  0.476615   \n",
       "ampl total power gamma.csv           48  4.570000e-07  5.779548  0.407658   \n",
       "ampl total power theta.csv           59  2.043252e-02 -3.406038  0.240243   \n",
       "...                                 ...           ...       ...       ...   \n",
       "std ampl gamma.csv                   48  6.130000e-07  5.729882  0.404155   \n",
       "std ampl theta.csv                   59  3.545612e-02 -3.251813  0.229365   \n",
       "waiting time beta.csv                49  1.259730e-04  4.660757  0.328744   \n",
       "waiting time delta.csv               40  3.580000e-06  5.422767  0.382493   \n",
       "waiting time gamma.csv               55  1.155290e-04  4.673827  0.329666   \n",
       "\n",
       "                            rcil_stat  rcih_stat  \n",
       "features                                          \n",
       "ampl total power alpha.csv       0.09       0.37  \n",
       "ampl total power beta.csv        0.11       0.40  \n",
       "ampl total power delta.csv       0.36       0.58  \n",
       "ampl total power gamma.csv       0.27       0.52  \n",
       "ampl total power theta.csv       0.10       0.37  \n",
       "...                               ...        ...  \n",
       "std ampl gamma.csv               0.28       0.52  \n",
       "std ampl theta.csv               0.09       0.36  \n",
       "waiting time beta.csv            0.20       0.45  \n",
       "waiting time delta.csv           0.25       0.50  \n",
       "waiting time gamma.csv           0.21       0.46  \n",
       "\n",
       "[108 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group comparison correlations and inertias\n",
    "# group comparison data\n",
    "data_mwu = pd.read_csv(os.path.join(results_3_dir, '3_mwu_r.csv'), index_col=0)\n",
    "\n",
    "# positive effect size indicates that older adults show higher values\n",
    "data_mwu['z_stat'] = data_mwu['z_stat'] * -1 \n",
    "data_mwu = data_mwu.loc[data_mwu['pvalues'] < 0.05]\n",
    "\n",
    "significant_analysis = len(data_mwu)\n",
    "\n",
    "# effect size directions\n",
    "positive_fx = len(np.where(data_mwu['z_stat'].values > 0)[0])\n",
    "negative_fx = len(np.where(data_mwu['z_stat'].values < 0)[0])\n",
    "# min and max significant effect\n",
    "min_fx = data_mwu.loc[data_mwu['r_stat'] == data_mwu['r_stat'].min()]\n",
    "max_fx = data_mwu.loc[data_mwu['r_stat'] == data_mwu['r_stat'].max()]\n",
    "\n",
    "print(significant_analysis,' EEG features showed significant group differences between young and older adults', significant_analysis/175)\n",
    "print(positive_fx,' EEG features showed a positive significant effect')\n",
    "print(negative_fx,' EEG features showed a negative significant effect')\n",
    "print('Mininum significant effect -> Feature : ',min_fx['r_stat'].index[0][:-4] , ', r value : ', min_fx['r_stat'][0])\n",
    "print('Maximum significant effect -> Feature : ',max_fx['r_stat'].index[0][:-4] , ', r value : ', max_fx['r_stat'][0])\n",
    "print('25, 50 and 75 percentles of significant r values: ',np.percentile(data_mwu['r_stat'],(25,50,75)))\n",
    "data_mwu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r_stat     0.25739\n",
       "z_stat     3.64914\n",
       "pvalues    0.01605\n",
       "Name: node str e-plv gamma.csv, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find group effect of EEG features\n",
    "data_mwu[['r_stat', 'z_stat','pvalues']].loc['node str e-plv gamma.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results section: Correlations between EEG features showing age-related differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations (25, 50, 75 percentiles) between EEG features showing significant effects for young adults :  [0.05913733 0.13286635 0.2864387 ]\n",
      "% of significant correlations between EEG features showing significant effects for young adults :  41.74454828660436\n",
      "\n",
      "Correlations (25, 50, 75 percentiles) between EEG features showing significant effects for older adults :  [0.07868904 0.16983487 0.3140841 ]\n",
      "% of significant correlations between EEG features showing significant effects for older adults :  33.766008999653856\n"
     ]
    }
   ],
   "source": [
    "# correlation between EEG features showing significant effects\n",
    "\n",
    "# for young adults\n",
    "corrs_y = pd.read_csv(os.path.join(results_4_dir,'4_correlation_eeg_y.csv'), index_col = 0)\n",
    "pvals_y = pd.read_csv(os.path.join(results_4_dir,'4_pvalues_eeg_y.csv'), index_col = 0)\n",
    "prc_corr_y = np.percentile(np.abs(corrs_y.values[np.triu_indices(len(corrs_y),1)]),(25,50,75))\n",
    "triu_pvals_y = pvals_y.values[np.triu_indices(len(pvals_y),1)]\n",
    "significant_corrs_y = len(np.where(triu_pvals_y < 0.05)[0])/len(triu_pvals_y)\n",
    "\n",
    "print('Correlations (25, 50, 75 percentiles) between EEG features showing significant effects for young adults : ', prc_corr_y)\n",
    "print('% of significant correlations between EEG features showing significant effects for young adults : ', significant_corrs_y*100)\n",
    "\n",
    "# for older adults\n",
    "corrs_o = pd.read_csv(os.path.join(results_4_dir,'4_correlation_eeg_o.csv'), index_col = 0)\n",
    "pvals_o = pd.read_csv(os.path.join(results_4_dir,'4_pvalues_eeg_o.csv'), index_col = 0)\n",
    "prc_corr_o = np.percentile(np.abs(corrs_o.values[np.triu_indices(len(corrs_o),1)]),(25,50,75))\n",
    "triu_pvals_o = pvals_o.values[np.triu_indices(len(pvals_o),1)]\n",
    "significant_corrs_o = len(np.where(triu_pvals_o < 0.05)[0])/len(triu_pvals_o)\n",
    "print()                                                            \n",
    "print('Correlations (25, 50, 75 percentiles) between EEG features showing significant effects for older adults : ', prc_corr_o)\n",
    "print('% of significant correlations between EEG features showing significant effects for older adults : ', significant_corrs_o*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate sqrt distance correlation (25, 50, 75 percentiles) between EEG features showing significant effects for young adults :  [0.12360455 0.23248131 0.41361325]\n",
      "% of significant distance correlations between EEG features showing significant effects for young adults :  58.53530377668309\n",
      "Multivariate sqrt distance correlation (25, 50, 75 percentiles) between EEG features showing significant effects for older adults :  [0.11925205 0.2111067  0.38294468]\n",
      "% of significant distance correlations between EEG features showing significant effects for older adults :  53.01142263759087\n"
     ]
    }
   ],
   "source": [
    "# multivariate distance correlation between EEG features showing significant effects\n",
    "# for young adults\n",
    "multivardc_y = pd.read_csv(os.path.join(results_5_dir,'5_dc_fx_y.csv'), index_col = 0)\n",
    "multivardcpvals_y = pd.read_csv(os.path.join(results_5_dir,'5_dc_pval_y.csv'), index_col = 0)\n",
    "multivardc_y = multivardc_y.loc[corrs_y.index][corrs_y.index]\n",
    "# get the sqrt of multivariate dc since it approximates the population squared distance correlation     \n",
    "prc_multivardc_y = np.percentile(np.sqrt(np.abs(multivardc_y.values[np.triu_indices(len(multivardc_y),1)])),(25,50,75))\n",
    "\n",
    "multivardc_y = multivardc_y.loc[corrs_y.index][corrs_y.index]\n",
    "triu_pvals_multivardc_y = multivardcpvals_y.values[np.triu_indices(len(multivardcpvals_y),1)]\n",
    "significant_multivardc_y = len(np.where(triu_pvals_multivardc_y < 0.05)[0])/len(triu_pvals_multivardc_y)\n",
    "                                                                \n",
    "print('Multivariate sqrt distance correlation (25, 50, 75 percentiles) between EEG features showing significant effects for young adults : ', prc_multivardc_y)\n",
    "print('% of significant distance correlations between EEG features showing significant effects for young adults : ', significant_multivardc_y*100)\n",
    "\n",
    "# for older adults\n",
    "multivardc_o = pd.read_csv(os.path.join(results_5_dir,'5_dc_fx_o.csv'), index_col = 0)\n",
    "multivardcpvals_o = pd.read_csv(os.path.join(results_5_dir,'5_dc_pval_o.csv'), index_col = 0)\n",
    "multivardc_o = multivardc_o.loc[corrs_o.index][corrs_o.index]\n",
    "# get the sqrt of multivariate dc since it approximates the population squared distance correlation     \n",
    "prc_multivardc_o = np.percentile(np.sqrt(np.abs(multivardc_o.values[np.triu_indices(len(multivardc_o),1)])),(25,50,75))\n",
    "multivardcpvals_o = multivardcpvals_o.loc[corrs_o.index][corrs_o.index]\n",
    "triu_pvals_multivardc_o = multivardcpvals_o.values[np.triu_indices(len(multivardcpvals_o),1)]\n",
    "significant_multivardc_o = len(np.where(triu_pvals_multivardc_o < 0.05)[0])/len(triu_pvals_multivardc_o)\n",
    "print('Multivariate sqrt distance correlation (25, 50, 75 percentiles) between EEG features showing significant effects for older adults : ', prc_multivardc_o)\n",
    "print('% of significant distance correlations between EEG features showing significant effects for older adults : ', significant_multivardc_o*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman:  0.83\n",
      "distcorr:  0.98\n"
     ]
    }
   ],
   "source": [
    "# Find correlations between EEG features\n",
    "# ['node str e-icoh delta']['clust coef e-icoh delta']\n",
    "# ['rqa laminarity']['rqa determinism']\n",
    "# ['waiting time gamma']['life time gamma']\n",
    "\n",
    "\n",
    "print('spearman: ', np.round(corrs_o['waiting time gamma']['life time gamma'], 2))\n",
    "print('distcorr: ', np.round(np.sqrt(np.abs(multivardc_o['waiting time gamma']['life time gamma'])), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of reference choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of comparing references in younger adults\n",
      "25, 50 and 75th percentiles of icc between average (csd for connectivity) and zero reference for young adults [0.56625 0.9195  0.96525]\n",
      "25, 50 and 75th percentiles of spearman correlations between average (csd for connectivity) and zero reference for young adults [0.67038213 0.90268477 0.97369911]\n",
      "25, 50 and 75th percentiles of multivariate correlations between average (csd for connectivity) and zero reference for young adults [0.78791708 0.98452908 0.99164168]\n",
      "\n",
      "Results of comparing references in older adults\n",
      "25, 50 and 75th percentiles of icc between average (csd for connectivity) and zero reference for older adults [0.6495  0.933   0.97425]\n",
      "25, 50 and 75th percentiles of spearman correlations between average (csd for connectivity) and zero reference for older adults [0.68355175 0.92554724 0.97835061]\n",
      "25, 50 and 75th percentiles of multivariate correlations between average (csd for connectivity) and zero reference for older adults [0.81368951 0.9874896  0.99544166]\n"
     ]
    }
   ],
   "source": [
    "# Compare results with difference references\n",
    "\n",
    "# For young adults\n",
    "icc_ref_y = pd.read_csv(os.path.join(results_7_dir,'7_icc_references_y.csv'), index_col = 0)\n",
    "spearman_ref_y = pd.read_csv(os.path.join(results_7_dir,'7_spearman_references_y.csv'), index_col = 0)\n",
    "multivardc_y_z = pd.read_csv(os.path.join(results_6_dir,'6_dc_fx_y.csv'), index_col = 0)\n",
    "\n",
    "# For older adults\n",
    "icc_ref_o = pd.read_csv(os.path.join(results_7_dir,'7_icc_references_o.csv'), index_col = 0)\n",
    "spearman_ref_o = pd.read_csv(os.path.join(results_7_dir,'7_spearman_references_o.csv'), index_col = 0)\n",
    "multivardc_o_z = pd.read_csv(os.path.join(results_6_dir,'6_dc_fx_o.csv'), index_col = 0)\n",
    "\n",
    "# Concatenate data\n",
    "# Younger adults data\n",
    "concat_y = pd.concat([np.round(icc_ref_y, 2), pd.DataFrame(np.round(np.sqrt(np.abs(np.diag(multivardc_y_z))), 2), columns=['multivardcor'],  index=icc_ref_y.index)], axis=1)\n",
    "concat_y.columns = ['ICC 25th', 'ICC 50th', 'ICC 75th', 'multivardcor']\n",
    "# Older adults data\n",
    "concat_o = pd.concat([np.round(icc_ref_o, 2), pd.DataFrame(np.round(np.sqrt(np.abs(np.diag(multivardc_o_z)))), columns=['multivardcor'],  index=icc_ref_o.index)], axis=1)\n",
    "concat_o.columns = ['ICC 25th', 'ICC 50th', 'ICC 75th', 'multivardcor']\n",
    "# All data\n",
    "all_cat = pd.concat([concat_y, concat_o], axis=1)\n",
    "all_cat.to_csv(os.path.join(summary_results_dir, 'reliability_reference.csv'))\n",
    "\n",
    "print(\"Results of comparing references in younger adults\")\n",
    "print(\"25, 50 and 75th percentiles of icc between average (csd for connectivity) and zero reference for young adults\", \n",
    "      np.percentile(icc_ref_y['50th'], (25, 50, 75)))\n",
    "print(\"25, 50 and 75th percentiles of spearman correlations between average (csd for connectivity) and zero reference for young adults\", \n",
    "      np.percentile(spearman_ref_y['50th'], (25, 50, 75)))\n",
    "print(\"25, 50 and 75th percentiles of multivariate correlations between average (csd for connectivity) and zero reference for young adults\", \n",
    "      np.percentile(np.sqrt(np.abs(np.diagonal(multivardc_y_z))), (25, 50, 75)))\n",
    "print()   \n",
    "print(\"Results of comparing references in older adults\")\n",
    "print(\"25, 50 and 75th percentiles of icc between average (csd for connectivity) and zero reference for older adults\", \n",
    "      np.percentile(icc_ref_o['50th'], (25, 50, 75)))\n",
    "print(\"25, 50 and 75th percentiles of spearman correlations between average (csd for connectivity) and zero reference for older adults\", \n",
    "      np.percentile(spearman_ref_o['50th'], (25, 50, 75)))\n",
    "print(\"25, 50 and 75th percentiles of multivariate correlations between average (csd for connectivity) and zero reference for older adults\", \n",
    "      np.percentile(np.sqrt(np.abs(np.diagonal(multivardc_o_z))), (25, 50, 75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate correlations, all 140 features in young adults\n",
      "25, 50, 75 percentile between all avg/csd features [0.10197995 0.19607684 0.37514465]\n",
      "25, 50, 75 percentile between all zero ref features [0.09431465 0.19253163 0.35833837]\n",
      "\n",
      "Multivariate correlations, all 140 features in older adults\n",
      "25, 50, 75 percentile between all avg/csd features [0.11562122 0.19598147 0.3474091 ]\n",
      "25, 50, 75 percentile between all zero ref features [0.10691003 0.17399355 0.33060365]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multivariate correlations between features with average(csd) and zero reference\n",
    "\n",
    "# List of zero ref features\n",
    "zero_ref_feats = list(multivardc_y_z)\n",
    "feat_index = [feature.replace(' zero','') for feature in zero_ref_feats]\n",
    "\n",
    "# Load multivariate data\n",
    "multivardc_y = pd.read_csv(os.path.join(results_5_dir,'5_dc_fx_y.csv'), index_col = 0)\n",
    "multivardc_o = pd.read_csv(os.path.join(results_5_dir,'5_dc_fx_o.csv'), index_col = 0)\n",
    "\n",
    "# Find in nonzero\n",
    "print('Multivariate correlations, all 140 features in young adults')\n",
    "print('25, 50, 75 percentile between all avg/csd features', np.percentile(np.sqrt(np.abs(multivardc_y.loc[feat_index][feat_index])).values[np.triu_indices(len(feat_index), 1)], (25, 50, 75)))\n",
    "print('25, 50, 75 percentile between all zero ref features', np.percentile(np.sqrt(np.abs(multivardc_y_z)).values[np.triu_indices(len(feat_index), 1)], (25, 50, 75)))\n",
    "print()\n",
    "print('Multivariate correlations, all 140 features in older adults')\n",
    "print('25, 50, 75 percentile between all avg/csd features', np.percentile(np.sqrt(np.abs(multivardc_o.loc[feat_index][feat_index])).values[np.triu_indices(len(feat_index), 1)], (25, 50, 75)))\n",
    "print('25, 50, 75 percentile between all zero ref features', np.percentile(np.sqrt(np.abs(multivardc_o_z)).values[np.triu_indices(len(feat_index), 1)], (25, 50, 75)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate correlations, 93 features showing group differences in young adults\n",
      "25, 50, 75 percentile between all avg/csd features [0.13137249 0.25170483 0.43610113]\n",
      "25, 50, 75 percentile between all zero ref features [0.13374477 0.24375938 0.44146497]\n",
      "\n",
      "Multivariate correlations, 93 features showing group differences in older adults\n",
      "25, 50, 75 percentile between all avg/csd features [0.12416478 0.21911936 0.40825509]\n",
      "25, 50, 75 percentile between all zero ref features [0.12327954 0.22861179 0.41491356]\n"
     ]
    }
   ],
   "source": [
    "# List of features showing group effects\n",
    "sign_feats = data_mwu.index\n",
    "sign_feat_index = [feature.replace('.csv','') for feature in sign_feats]\n",
    "\n",
    "# Remove source space features\n",
    "sign_feat_index = [item for item in sign_feat_index if 's-' not in item]\n",
    "sign_feat_index = [item for item in sign_feat_index if 'source' not in item]\n",
    "sign_feat_index_z = [s + ' zero' for s in sign_feat_index]\n",
    "\n",
    "# Get correlations\n",
    "# For younger adults\n",
    "zero_y = np.sqrt(np.abs(multivardc_y_z.loc[sign_feat_index_z][sign_feat_index_z])).values[np.triu_indices(len(sign_feat_index_z),1)]\n",
    "avg_csd_y = np.sqrt(np.abs(multivardc_y.loc[sign_feat_index][sign_feat_index])).values[np.triu_indices(len(sign_feat_index),1)]\n",
    "\n",
    "# For older adults\n",
    "zero_o = np.sqrt(np.abs(multivardc_o_z.loc[sign_feat_index_z][sign_feat_index_z])).values[np.triu_indices(len(sign_feat_index_z),1)]\n",
    "avg_csd_o = np.sqrt(np.abs(multivardc_o.loc[sign_feat_index][sign_feat_index])).values[np.triu_indices(len(sign_feat_index),1)]\n",
    "\n",
    "\n",
    "# Find in nonzero\n",
    "print('Multivariate correlations, 93 features showing group differences in young adults')\n",
    "print('25, 50, 75 percentile between all avg/csd features', np.percentile(zero_y, (25, 50, 75)))\n",
    "print('25, 50, 75 percentile between all zero ref features', np.percentile(avg_csd_y, (25, 50, 75)))\n",
    "print()\n",
    "print('Multivariate correlations, 93 features showing group differences in older adults')\n",
    "print('25, 50, 75 percentile between all avg/csd features', np.percentile(zero_o, (25, 50, 75)))\n",
    "print('25, 50, 75 percentile between all zero ref features', np.percentile(avg_csd_o, (25, 50, 75)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stats_eeg]",
   "language": "python",
   "name": "conda-env-stats_eeg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
